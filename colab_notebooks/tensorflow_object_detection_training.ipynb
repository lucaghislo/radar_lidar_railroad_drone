{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensorflow_object_detection.ipynb","provenance":[],"collapsed_sections":["KNT9cI_ZSCla","Iz1sd2reSTxg"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install \"opencv-python-headless<4.3\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NazICFVfb0ez","executionInfo":{"status":"ok","timestamp":1646641600155,"user_tz":-60,"elapsed":7678,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}},"outputId":"b1f42c30-2b7a-45d3-889a-3bb3bd4b0043"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless<4.3 in /usr/local/lib/python3.7/dist-packages (4.2.0.34)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless<4.3) (1.21.5)\n"]}]},{"cell_type":"markdown","source":["## Installation"],"metadata":{"id":"KNT9cI_ZSCla"}},{"cell_type":"code","execution_count":null,"source":["!pip install tensorflow==\"2.6.0\""],"outputs":[],"metadata":{"id":"fTBYWlnKSD78"}},{"cell_type":"code","execution_count":null,"source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"outputs":[],"metadata":{"id":"Kpha2-F_SGBj"}},{"cell_type":"code","execution_count":null,"source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"outputs":[],"metadata":{"id":"rmr2UdV_SHuc"}},{"cell_type":"code","execution_count":null,"source":["#run model builder test\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"],"outputs":[],"metadata":{"id":"XzXxTBXHSNqA"}},{"cell_type":"markdown","source":["## Prepare data"],"metadata":{"id":"Iz1sd2reSTxg"}},{"cell_type":"code","execution_count":null,"source":["# Install Kaggle API\n","!pip install -q kaggle\n","!pip install -q kaggle-cli"],"outputs":[{"output_type":"stream","name":"stdout","text":["  Building wheel for lxml (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for lxml\u001b[0m\n","\u001b[?25h    Running setup.py install for lxml ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-af770x0p/lxml_18e89bdd49d74ce78e6b406980e74f7e/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-af770x0p/lxml_18e89bdd49d74ce78e6b406980e74f7e/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-nlrkhhj1/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/lxml Check the logs for full command output.\u001b[0m\n"]}],"metadata":{"id":"N8XSaOzhSX-n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f9baaf5f-e33a-465f-8002-a86b484ce93d","executionInfo":{"status":"ok","timestamp":1646641772395,"user_tz":-60,"elapsed":24934,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}}}},{"cell_type":"code","execution_count":null,"source":["# only for google colab\n","import os\n","os.environ['KAGGLE_USERNAME'] = \"<username>\" \n","os.environ['KAGGLE_KEY'] = \"<key>\""],"outputs":[],"metadata":{"id":"SQqz-fsJbiQ0"}},{"cell_type":"code","execution_count":null,"source":["!kaggle datasets download -d tannergi/microcontroller-detection --unzip"],"outputs":[{"output_type":"stream","name":"stdout","text":["401 - Unauthorized\n"]}],"metadata":{"id":"cozgoQPEbo-k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"13bb817c-8584-4af9-fbd9-730a3ef1f8f0","executionInfo":{"status":"ok","timestamp":1646641773030,"user_tz":-60,"elapsed":647,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}}}},{"cell_type":"code","execution_count":null,"source":["!mv \"Microcontroller Detection\" microcontroller-detection"],"outputs":[{"output_type":"stream","name":"stdout","text":["mv: cannot stat 'Microcontroller Detection': No such file or directory\n"]}],"metadata":{"id":"LbRcqKh5b-j7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646641773030,"user_tz":-60,"elapsed":7,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}},"outputId":"59c29423-efe9-49e4-c03b-567a65912f28"}},{"cell_type":"code","execution_count":null,"source":["!wget https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/generate_tfrecord.py"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-07 08:29:32--  https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/generate_tfrecord.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3470 (3.4K) [text/plain]\n","Saving to: ‘generate_tfrecord.py.2’\n","\n","generate_tfrecord.p 100%[===================>]   3.39K  --.-KB/s    in 0s      \n","\n","2022-03-07 08:29:32 (28.5 MB/s) - ‘generate_tfrecord.py.2’ saved [3470/3470]\n","\n"]}],"metadata":{"id":"3KHDdTY_cm5G","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a362803-ebbb-48fc-b61d-64f1adffa7a0","executionInfo":{"status":"ok","timestamp":1646641773330,"user_tz":-60,"elapsed":305,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}}}},{"cell_type":"code","execution_count":null,"source":["!wget https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/training/labelmap.pbtxt"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-07 08:29:32--  https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/training/labelmap.pbtxt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 177 [text/plain]\n","Saving to: ‘labelmap.pbtxt.2’\n","\n","labelmap.pbtxt.2    100%[===================>]     177  --.-KB/s    in 0s      \n","\n","2022-03-07 08:29:32 (4.90 MB/s) - ‘labelmap.pbtxt.2’ saved [177/177]\n","\n"]}],"metadata":{"id":"5IRZfTu6di4R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"08b06c2e-3a92-4793-efde-5e7a03e5f632","executionInfo":{"status":"ok","timestamp":1646641773514,"user_tz":-60,"elapsed":186,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}}}},{"cell_type":"code","execution_count":null,"source":["!python generate_tfrecord.py --csv_input=microcontroller-detection/train_labels.csv --image_dir=microcontroller-detection/train --output_path=train.record\n","!python generate_tfrecord.py --csv_input=microcontroller-detection/test_labels.csv --image_dir=microcontroller-detection/test --output_path=test.record"],"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"generate_tfrecord.py\", line 103, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"generate_tfrecord.py\", line 91, in main\n","    examples = pd.read_csv(FLAGS.csv_input)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n","    return _read(filepath_or_buffer, kwds)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 482, in _read\n","    parser = TextFileReader(filepath_or_buffer, **kwds)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n","    self._engine = self._make_engine(self.engine)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n","    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n","    self._open_handles(src, kwds)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\", line 229, in _open_handles\n","    errors=kwds.get(\"encoding_errors\", \"strict\"),\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\", line 707, in get_handle\n","    newline=\"\",\n","FileNotFoundError: [Errno 2] No such file or directory: 'microcontroller-detection/train_labels.csv'\n","Traceback (most recent call last):\n","  File \"generate_tfrecord.py\", line 103, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"generate_tfrecord.py\", line 91, in main\n","    examples = pd.read_csv(FLAGS.csv_input)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n","    return _read(filepath_or_buffer, kwds)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 482, in _read\n","    parser = TextFileReader(filepath_or_buffer, **kwds)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n","    self._engine = self._make_engine(self.engine)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n","    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n","    self._open_handles(src, kwds)\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\", line 229, in _open_handles\n","    errors=kwds.get(\"encoding_errors\", \"strict\"),\n","  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\", line 707, in get_handle\n","    newline=\"\",\n","FileNotFoundError: [Errno 2] No such file or directory: 'microcontroller-detection/test_labels.csv'\n"]}],"metadata":{"id":"hs4KdOs7coyX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de617bcf-b8a4-489b-cf1a-a87f9c70415b","executionInfo":{"status":"ok","timestamp":1646641788863,"user_tz":-60,"elapsed":15351,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}}}},{"cell_type":"code","execution_count":null,"source":["train_record_path = '/content/train.record'\n","test_record_path = '/content/test.record'\n","labelmap_path = '/content/labelmap.pbtxt'"],"outputs":[],"metadata":{"id":"Z_W_8L24c4Sk"}},{"cell_type":"markdown","source":["## Configuring training"],"metadata":{"id":"SK79i98YSY8a"}},{"cell_type":"code","execution_count":null,"source":["batch_size = 16\n","num_steps = 8000\n","num_eval_steps = 1000"],"outputs":[],"metadata":{"id":"Axko9Jd0hEI3"}},{"cell_type":"code","execution_count":null,"source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-07 08:29:48--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 209.85.234.128, 2607:f8b0:4001:c17::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|209.85.234.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30736482 (29M) [application/x-tar]\n","Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz.2’\n","\n","efficientdet_d0_coc 100%[===================>]  29.31M   132MB/s    in 0.2s    \n","\n","2022-03-07 08:29:48 (132 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz.2’ saved [30736482/30736482]\n","\n"]}],"metadata":{"id":"8RNI68K_dyzX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eaaf82f7-5018-4b01-ab51-36a6c29ba2ef","executionInfo":{"status":"ok","timestamp":1646641790487,"user_tz":-60,"elapsed":1634,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}}}},{"cell_type":"code","execution_count":null,"source":["fine_tune_checkpoint = 'efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'"],"outputs":[],"metadata":{"id":"HKENdH3TfhGb"}},{"cell_type":"code","execution_count":null,"source":["!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n","\n","base_config_path = 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config'"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-07 08:29:49--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4630 (4.5K) [text/plain]\n","Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.2’\n","\n","\r          ssd_effic   0%[                    ]       0  --.-KB/s               \rssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n","\n","2022-03-07 08:29:49 (31.1 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.2’ saved [4630/4630]\n","\n"]}],"metadata":{"id":"qzQ84qIQelJB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"15dd03b6-5240-496a-c34a-010337b73935","executionInfo":{"status":"ok","timestamp":1646641790799,"user_tz":-60,"elapsed":314,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}}}},{"cell_type":"code","execution_count":null,"source":["# edit configuration file (from https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD)\n","\n","import re\n","\n","with open(base_config_path) as f:\n","    config = f.read()\n","\n","with open('model_config.config', 'w') as f:\n","  \n","  # Set labelmap path\n","  config = re.sub('label_map_path: \".*?\"', \n","             'label_map_path: \"{}\"'.format(labelmap_path), config)\n","  \n","  # Set fine_tune_checkpoint path\n","  config = re.sub('fine_tune_checkpoint: \".*?\"',\n","                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n","  \n","  # Set train tf-record file path\n","  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n","                  'input_path: \"{}\"'.format(train_record_path), config)\n","  \n","  # Set test tf-record file path\n","  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n","                  'input_path: \"{}\"'.format(test_record_path), config)\n","  \n","  # Set number of classes.\n","  config = re.sub('num_classes: [0-9]+',\n","                  'num_classes: {}'.format(4), config)\n","  \n","  # Set batch size\n","  config = re.sub('batch_size: [0-9]+',\n","                  'batch_size: {}'.format(batch_size), config)\n","  \n","  # Set training steps\n","  config = re.sub('num_steps: [0-9]+',\n","                  'num_steps: {}'.format(num_steps), config)\n","  \n","  # Set fine-tune checkpoint type to detection\n","  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n","             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n","  \n","  f.write(config)"],"outputs":[],"metadata":{"id":"m3ehVTRgesxS"}},{"cell_type":"code","execution_count":null,"source":["%cat model_config.config"],"outputs":[{"output_type":"stream","name":"stdout","text":[" # SSD with EfficientNet-b0 + BiFPN feature extractor,\n","# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n","# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n","# See Lin et al, https://arxiv.org/abs/1708.02002\n","# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n","#\n","# Train on TPU-8\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 4\n","    add_background_class: false\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: [1.0, 2.0, 0.5]\n","        scales_per_octave: 3\n","      }\n","    }\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 512\n","        max_dimension: 512\n","        pad_to_max_dimension: true\n","        }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        depth: 64\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          force_use_bias: true\n","          activation: SWISH\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            scale: true\n","            decay: 0.99\n","            epsilon: 0.001\n","          }\n","        }\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        use_depthwise: true\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_efficientnet-b0_bifpn_keras'\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 3\n","        num_filters: 64\n","      }\n","      conv_hyperparams {\n","        force_use_bias: true\n","        activation: SWISH\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          scale: true,\n","          decay: 0.99,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.25\n","          gamma: 1.5\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint: \"efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 16\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  use_bfloat16: true\n","  num_steps: 8000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_scale_crop_and_pad_to_square {\n","      output_size: 512\n","      scale_min: 0.1\n","      scale_max: 2.0\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 8e-2\n","          total_steps: 300000\n","          warmup_learning_rate: .001\n","          warmup_steps: 2500\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/labelmap.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 16;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/labelmap.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/test.record\"\n","  }\n","}\n"]}],"metadata":{"id":"SmtrS5dihpS_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a4bfb42-c8c9-4074-e62e-88e784a0a63e","executionInfo":{"status":"ok","timestamp":1646641791089,"user_tz":-60,"elapsed":291,"user":{"displayName":"Luca Ghislotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDNF0vjtd44lqI3QQyFP9PsIKccuAVBwAPMuNNCQ=s64","userId":"04176872480832526846"}}}},{"cell_type":"code","execution_count":null,"source":["model_dir = 'training/'\n","pipeline_config_path = 'model_config.config'"],"outputs":[],"metadata":{"id":"eRTBSsYthwxG"}},{"cell_type":"markdown","source":["## Train detector"],"metadata":{"id":"Tv0sbQlciKWA"}},{"cell_type":"code","execution_count":null,"source":["!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_config_path} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1 \\\n","    --num_eval_steps={num_eval_steps}"],"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-03-07 08:29:58.134437: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0307 08:29:58.141162 140455509366656 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 8000\n","I0307 08:29:58.146311 140455509366656 config_util.py:552] Maybe overwriting train_steps: 8000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0307 08:29:58.146507 140455509366656 config_util.py:552] Maybe overwriting use_bfloat16: False\n","I0307 08:29:58.159285 140455509366656 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0307 08:29:58.159673 140455509366656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0307 08:29:58.159857 140455509366656 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0307 08:29:58.164696 140455509366656 efficientnet_model.py:144] round_filter input=32 output=32\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.189903 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.192217 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.195120 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.196391 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.205625 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.210092 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.218610 140455509366656 efficientnet_model.py:144] round_filter input=32 output=32\n","I0307 08:29:58.218757 140455509366656 efficientnet_model.py:144] round_filter input=16 output=16\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.237626 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.238977 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.241517 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.242785 140455509366656 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0307 08:29:58.351045 140455509366656 efficientnet_model.py:144] round_filter input=16 output=16\n","I0307 08:29:58.351301 140455509366656 efficientnet_model.py:144] round_filter input=24 output=24\n","I0307 08:29:58.709069 140455509366656 efficientnet_model.py:144] round_filter input=24 output=24\n","I0307 08:29:58.709332 140455509366656 efficientnet_model.py:144] round_filter input=40 output=40\n","I0307 08:29:59.064285 140455509366656 efficientnet_model.py:144] round_filter input=40 output=40\n","I0307 08:29:59.064521 140455509366656 efficientnet_model.py:144] round_filter input=80 output=80\n","I0307 08:29:59.611489 140455509366656 efficientnet_model.py:144] round_filter input=80 output=80\n","I0307 08:29:59.611751 140455509366656 efficientnet_model.py:144] round_filter input=112 output=112\n","I0307 08:30:00.143434 140455509366656 efficientnet_model.py:144] round_filter input=112 output=112\n","I0307 08:30:00.143721 140455509366656 efficientnet_model.py:144] round_filter input=192 output=192\n","I0307 08:30:00.847225 140455509366656 efficientnet_model.py:144] round_filter input=192 output=192\n","I0307 08:30:00.847454 140455509366656 efficientnet_model.py:144] round_filter input=320 output=320\n","I0307 08:30:01.015012 140455509366656 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0307 08:30:01.081407 140455509366656 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0307 08:30:01.140549 140455509366656 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/train.record']\n","I0307 08:30:01.146241 140455509366656 dataset_builder.py:163] Reading unweighted datasets: ['/content/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/train.record']\n","I0307 08:30:01.146471 140455509366656 dataset_builder.py:80] Reading record datasets for input file: ['/content/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0307 08:30:01.146618 140455509366656 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0307 08:30:01.146771 140455509366656 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0307 08:30:01.149412 140455509366656 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0307 08:30:01.173497 140455509366656 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0307 08:30:10.628461 140455509366656 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0307 08:30:16.027166 140455509366656 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"]}],"metadata":{"id":"t2zxx5AXiNNK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a2c41828-af76-47aa-a9b4-3432b66d6b8e"}},{"cell_type":"code","execution_count":null,"source":["%load_ext tensorboard\n","%tensorboard --logdir '/content/training/train'"],"outputs":[],"metadata":{"id":"PK8amcT_wgVb"}},{"cell_type":"markdown","source":["## Export model inference graph"],"metadata":{"id":"U3GNLS4ywstA"}},{"cell_type":"code","execution_count":null,"source":["output_directory = 'inference_graph'\n","\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir {model_dir} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_config_path}"],"outputs":[],"metadata":{"id":"WcvbNjcZw2er"}},{"cell_type":"code","execution_count":null,"source":["from google.colab import files\n","files.download(f'/content/{output_directory}/saved_model/saved_model.pb') "],"outputs":[],"metadata":{"id":"LcWVXuGAxeZ4"}},{"cell_type":"markdown","source":["## Test trained model on test images"],"metadata":{"id":"5tGVwzpLxvSv"}},{"cell_type":"code","execution_count":null,"source":["import io\n","import os\n","import scipy.misc\n","import numpy as np\n","import six\n","import time\n","import glob\n","from IPython.display import display\n","\n","from six import BytesIO\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","%matplotlib inline"],"outputs":[],"metadata":{"id":"hp4wlWrhxyJL"}},{"cell_type":"code","execution_count":null,"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path (this can be local or on colossus)\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"outputs":[],"metadata":{"id":"NEaYWo8WyLS2"}},{"cell_type":"code","execution_count":null,"source":["category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)"],"outputs":[],"metadata":{"id":"OxWU7K_oyVwq"}},{"cell_type":"code","execution_count":null,"source":["tf.keras.backend.clear_session()\n","model = tf.saved_model.load(f'/content/{output_directory}/saved_model')"],"outputs":[],"metadata":{"id":"bkMddTneyesG"}},{"cell_type":"code","execution_count":null,"source":["def run_inference_for_single_image(model, image):\n","  image = np.asarray(image)\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tf.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tf.newaxis,...]\n","\n","  # Run inference\n","  model_fn = model.signatures['serving_default']\n","  output_dict = model_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.\n","  num_detections = int(output_dict.pop('num_detections'))\n","  output_dict = {key:value[0, :num_detections].numpy() \n","                 for key,value in output_dict.items()}\n","  output_dict['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","   \n","  # Handle models with masks:\n","  if 'detection_masks' in output_dict:\n","    # Reframe the the bbox mask to the image size.\n","    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","              output_dict['detection_masks'], output_dict['detection_boxes'],\n","               image.shape[0], image.shape[1])      \n","    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                       tf.uint8)\n","    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","    \n","  return output_dict"],"outputs":[],"metadata":{"id":"kxAf3XJBzLHq"}},{"cell_type":"code","execution_count":null,"source":["for image_path in glob.glob('microcontroller-detection/test/*.jpg'):\n","  image_np = load_image_into_numpy_array(image_path)\n","  output_dict = run_inference_for_single_image(model, image_np)\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks_reframed', None),\n","      use_normalized_coordinates=True,\n","      line_thickness=8)\n","  display(Image.fromarray(image_np))"],"outputs":[],"metadata":{"id":"EEX-m3P1yp4y"}}]}